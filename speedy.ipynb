{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import colorsys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n",
    "from yolo3.utils import letterbox_image\n",
    "from keras.utils import multi_gpu_model\n",
    "gpu_num=1\n",
    "\n",
    "#- Added\n",
    "import cv2\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('../../gopro/021405.mp4')\n",
    "camera_scale = 1.\n",
    "#-\n",
    "\n",
    "import csv\n",
    "import glob \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mutagen.mp3 import MP3 as mp3\n",
    "import pygame\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process\n",
    "import multiprocessing as multi\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"../../img_data\"\n",
    "\n",
    "# devide into car, walker, others\n",
    "model = load_model('history/use_res_12.h5')\n",
    "\n",
    "# color range\n",
    "lower_red = [[140,50,50],[0,50,50]]\n",
    "upper_red = [[180,255,255],[10,255,255]]\n",
    "\n",
    "lower_green = [35, 50, 50]\n",
    "upper_green = [95, 255, 255]\n",
    "\n",
    "# setting the threshold\n",
    "threshold = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO(object):\n",
    "    def __init__(self):\n",
    "        start1 = timer()\n",
    "        self.model_path = '../../model_data/yolo.h5' # model path or trained weights path\n",
    "        self.anchors_path = '../../model_data/yolo_anchors.txt'\n",
    "        self.classes_path = '../../model_data/coco_classes.txt'\n",
    "        self.score = 0.3\n",
    "        self.iou = 0.45\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.model_image_size = (416, 416) # fixed size or (None, None), hw\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "        self.count = 0\n",
    "        self.num = 0\n",
    "        self.zeroarray = np.zeros(9)\n",
    "        self.flag = 3*np.ones(100)\n",
    "        self.passtime = 0\n",
    "        self.colorval = {0:(0, 255, 0), 1:(255,0,0), 2:(0, 0, 255), 3:(255,255,255)}\n",
    "        end1 = timer()\n",
    "        print(\"init time:\" + str(end1 - start1))\n",
    "\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        if gpu_num>=2:\n",
    "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=gpu_num)\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def detect_image(self, image):\n",
    "        start = timer()\n",
    "\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "#         print(image_data.shape)\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "\n",
    "#         print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "        font = ImageFont.truetype(font='../../font/FiraMono-Medium.otf',\n",
    "                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "        thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "        \n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "            if predicted_class == 'traffic light':\n",
    "                label = '{} {:.2f}'.format(predicted_class, score)\n",
    "                draw = ImageDraw.Draw(image)\n",
    "                label_size = draw.textsize(label, font)\n",
    "\n",
    "                top, left, bottom, right = box\n",
    "                top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "                left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "                bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "                right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "                cropped_img = image.crop((left, top, right, bottom))\n",
    "                file_name = f\"../../img_data/rectangle/{self.count}.jpg\"\n",
    "                \n",
    "                # remove car traffic light and other noise\n",
    "                new_img = pil2cv(cropped_img)\n",
    "                resize_img = np.array(cv2pil(cv2.resize(preprocess(new_img), dsize=(32, 32))))/255.0\n",
    "                data = resize_img.reshape((1, 32, 32, 3))\n",
    "                pred = model.predict(data)\n",
    "                bestnum  = 0.0\n",
    "                bestclass = 0\n",
    "                for n in [0,1,2,3]:\n",
    "                    if bestnum < pred[0][n]:\n",
    "                        bestnum = pred[0][n]\n",
    "                        bestclass = n\n",
    "                #color_prediction\n",
    "                if (bestclass==0) or (bestclass==1):\n",
    "                    red = color_extraction(cropped_img, 'red', lower_red, upper_red)\n",
    "                    green = color_extraction(cropped_img, 'green', lower_green, upper_green)\n",
    "                    red_ratio = color_ratio(red, \"red\", threshold)\n",
    "                    green_ratio = color_ratio(green,  \"green\", threshold)\n",
    "                    string = color_predict(red_ratio, green_ratio)\n",
    "                    judge_count, new_flag = majority(string, self.zeroarray, self.num)\n",
    "                    self.flag[judge_count] = new_flag\n",
    "                    if self.flag[judge_count-1] != new_flag:\n",
    "                        cmd = f\"python soundon.py {new_flag}\"\n",
    "#                         print(self.flag)\n",
    "                        if self.flag[judge_count-1]!=3:\n",
    "                            cmd2 = f\"python soundon.py {3}\"\n",
    "                            subprocess.Popen(cmd2.split())\n",
    "                        if new_flag == 0:\n",
    "                            color_print(new_flag)\n",
    "                            subprocess.Popen(cmd.split())\n",
    "                        elif new_flag == 1:\n",
    "                            subprocess.Popen(cmd.split())\n",
    "                            color_print(new_flag)\n",
    "                        else:\n",
    "#                             subprocess.Popen(cmd.split())\n",
    "                            color_print(new_flag)\n",
    "                    self.num += 1\n",
    "                self.count += 1\n",
    "\n",
    "                if top - label_size[1] >= 0:\n",
    "                    text_origin = np.array([left, top - label_size[1]])\n",
    "                else:\n",
    "                    text_origin = np.array([left, top + 1])\n",
    "\n",
    "                # My kingdom for a good redistributable image drawing library.\n",
    "                for i in range(thickness):\n",
    "                    draw.rectangle(\n",
    "                        [left + i, top + i, right - i, bottom - i],\n",
    "                        outline=self.colors[c])\n",
    "                draw.rectangle(\n",
    "                    [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                    fill=self.colors[c])\n",
    "                draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "                print(label)\n",
    "                del draw\n",
    "\n",
    "                end = timer()\n",
    "                dur = end - start \n",
    "        return image\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_img(yolo):\n",
    "    num = 0\n",
    "    tm = cv2.TickMeter()\n",
    "    tm.start()\n",
    "\n",
    "    fps = 0\n",
    "    sumtime = 0\n",
    "    tdf = 0\n",
    "    flame = 0\n",
    "    dfa = np.zeros((10000))\n",
    "    yoloFlag = True\n",
    "    flagnum = 0\n",
    "    \n",
    "    while True:\n",
    "        start2 = timer()\n",
    "        ret, image = cap.read()\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            break\n",
    "        if ret == False:\n",
    "            break\n",
    "        if yoloFlag:\n",
    "            if flagnum > 0:\n",
    "                for i in range(20):\n",
    "                    cv2.rectangle(image,(80-4*i,20-i),(80+4*i, 20+i),(60,60,60),3)\n",
    "#                 cv2.rectangle(image,(0,0),(160,40),(40,40,40),3,-1)ret, image = cap.read()\n",
    "                fps = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                fps /= 1000\n",
    "                cv2.putText(image, 'FPS:{:.1f}'.format(fps),(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (220, 220, 220), thickness=2)\n",
    "                h, w = image.shape[:2]\n",
    "                rh = int(h * camera_scale)\n",
    "                rw = int(w * camera_scale)\n",
    "                image = cv2.resize(image, (rw, rh))\n",
    "                image = image[:,:,(2,1,0)]\n",
    "                image = Image.fromarray(image)\n",
    "                r_image = yolo.detect_image(image)\n",
    "                out_img = np.array(r_image)[:,:,(2,1,0)]\n",
    "                cv2.imshow(\"YOLOv2\", np.array(out_img))\n",
    "                end2 = timer()\n",
    "                eachtime = end2 - start2\n",
    "                tdf += eachtime - 1/30\n",
    "                sumtime += eachtime\n",
    "                if tdf*30 > 1:\n",
    "                    dfa[flagnum] += int(tdf*30)\n",
    "                    yoloFlag = False\n",
    "                    flagnum += 1\n",
    "            else:\n",
    "                fps = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                fps /= 1000\n",
    "                cv2.putText(image, 'FPS: {:.1f}'.format(fps),(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), thickness=2)\n",
    "                h, w = image.shape[:2]\n",
    "                rh = int(h * camera_scale)\n",
    "                rw = int(w * camera_scale)\n",
    "                image = cv2.resize(image, (rw, rh))\n",
    "                image = image[:,:,(2,1,0)]\n",
    "                image = Image.fromarray(image)\n",
    "                r_image = yolo.detect_image(image)\n",
    "                out_img = np.array(r_image)[:,:,(2,1,0)]\n",
    "                cv2.imshow(\"YOLOv2\", np.array(out_img))\n",
    "                end2 = timer()\n",
    "                eachtime = end2 - start2\n",
    "                if num == 1:\n",
    "                    tdf += eachtime - 1/30\n",
    "                    sumtime += eachtime\n",
    "                    if tdf*30 > 1:                        \n",
    "                        dfa[flagnum] += int(tdf*30)\n",
    "                        yoloFlag = False\n",
    "                        flagnum += 1\n",
    "        else:\n",
    "            end2_2 = timer()\n",
    "            eachtime = end2_2 - start2\n",
    "            sumtime += eachtime\n",
    "            tdf += eachtime\n",
    "            tdf -= 1/30\n",
    "            dfa[flagnum -1] -= 1\n",
    "            if dfa[flagnum-1] == 0:\n",
    "                yoloFlag = True\n",
    "        num += 1\n",
    "        \n",
    "    print('sum eachtime:' + str(sumtime))\n",
    "    yolo.close_session()\n",
    "            \n",
    "def numericalSort(value):\n",
    "    numbers = re.compile(r'(\\d+)')\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "def get_img_path(dir_name:str, version:str):\n",
    "    files = f\"{dir_name}/{version}/\"\n",
    "    img_path = sorted(glob.glob(str(files+\"*.jpg\")), key=numericalSort)\n",
    "    return img_path           \n",
    "\n",
    "def preprocess(img):\n",
    "    h, w, c = img.shape\n",
    "    longest_edge = max(h, w)\n",
    "    top = 0\n",
    "    bottom = 0\n",
    "    left = 0\n",
    "    right = 0\n",
    "    if h < longest_edge:\n",
    "        diff_h = longest_edge - h\n",
    "        top = diff_h // 2\n",
    "        bottom = diff_h - top\n",
    "    elif w < longest_edge:\n",
    "        diff_w = longest_edge - w\n",
    "        left = diff_w // 2\n",
    "        right = diff_w - left\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right,\n",
    "                             cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    return img\n",
    "\n",
    "def cv2pil(image):\n",
    "    ''' OpenCV型 -> PIL型 '''\n",
    "    new_image = image.copy()\n",
    "    if new_image.ndim == 2:  # モノクロ\n",
    "        pass\n",
    "    elif new_image.shape[2] == 3:  # カラー\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)\n",
    "    elif new_image.shape[2] == 4:  # 透過\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_BGRA2RGBA)\n",
    "    new_image = Image.fromarray(new_image)\n",
    "    return new_image\n",
    "\n",
    "def pil2cv(image):\n",
    "    ''' PIL型 -> OpenCV型 '''\n",
    "    new_image = np.array(image, dtype=np.uint8)\n",
    "    if new_image.ndim == 2:  # モノクロ\n",
    "        pass\n",
    "    elif new_image.shape[2] == 3:  # カラー\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR)\n",
    "    elif new_image.shape[2] == 4:  # 透過\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGBA2BGRA)\n",
    "    return new_image\n",
    "\n",
    "#Phase2:color extracting\n",
    "#create color mask\n",
    "def create_mask(color:str, lower_color:list, upper_color:list, img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    if color == 'red':\n",
    "        lower_red1 = np.array(lower_color[0])\n",
    "        upper_red1 = np.array(upper_color[0])\n",
    "        lower_red2 = np.array(lower_color[1])\n",
    "        upper_red2 = np.array(upper_color[1])\n",
    "        red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "        red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "        mask = red_mask1 + red_mask2\n",
    "    else:\n",
    "        lower_color = np.array(lower_color)\n",
    "        upper_color = np.array(upper_color)\n",
    "        mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    return mask\n",
    "\n",
    "def color_extraction(cropped_img:list, color:str, lower_color:list, upper_color:list):\n",
    "    img = pil2cv(cropped_img)\n",
    "    mask = create_mask(color, lower_color, upper_color, img)\n",
    "    target = cv2.bitwise_and(img, img, mask=mask)\n",
    "    return target\n",
    "        \n",
    "def color_ratio(color_pic:str, color:str, threshold:int):\n",
    "    img = cv2.cvtColor(color_pic, cv2.COLOR_RGB2GRAY)\n",
    "    ret, img_thresh = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n",
    "    colorPixels = cv2.countNonZero(img_thresh)\n",
    "    wholeSize = img.size\n",
    "    color_ratio = colorPixels/wholeSize*100\n",
    "    return color_ratio\n",
    "\n",
    "def color_predict(red:list, green:list):\n",
    "    if red > green:\n",
    "        if red > 5:\n",
    "            return('Red')\n",
    "        else:\n",
    "            return('NaN')\n",
    "    elif green > red:            \n",
    "        if green > 5:\n",
    "            return('Green')\n",
    "        else:\n",
    "            return('NaN')\n",
    "    else:\n",
    "        return('NaN')\n",
    "\n",
    "\n",
    "def majority(string:str, zerolist:list, num:int):\n",
    "    frames = 9\n",
    "    print(zerolist)\n",
    "    if num < frames:\n",
    "        fps = num\n",
    "    else:\n",
    "        fps = num - (num // frames) * frames\n",
    "    if 'Red' in string:\n",
    "        zerolist[fps] = 0\n",
    "    elif 'Green' in string:\n",
    "        zerolist[fps] = 1\n",
    "    else:\n",
    "        zerolist[fps] = 'NaN'\n",
    "    if fps == frames-1:\n",
    "        nans = np.count_nonzero(np.isnan(zerolist))\n",
    "        ones = np.count_nonzero(zerolist)-nans\n",
    "        zeros = zerolist.shape[0]-ones-nans\n",
    "        judge_count = num // frames + 1\n",
    "        if (zeros > ones):\n",
    "            return judge_count, 0\n",
    "        elif (ones > zeros):\n",
    "            return judge_count, 1\n",
    "        else:\n",
    "            return judge_count, 2\n",
    "    else:\n",
    "        return 0, 3\n",
    "    \n",
    "def color_print(new_flag:int):\n",
    "    color = {0:\"'''red!!!'''\", 1:\"'''green!!!'''\", 2:\"'''idk!!!'''\"}\n",
    "    print(color[new_flag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../model_data/yolo.h5 model, anchors, and classes loaded.\n",
      "init time:10.23952669207938\n",
      "traffic light 0.40\n",
      "traffic light 0.54\n",
      "traffic light 0.67\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.77\n",
      "traffic light 0.56\n",
      "traffic light 0.69\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.78\n",
      "traffic light 0.45\n",
      "traffic light 0.64\n",
      "traffic light 0.66\n",
      "traffic light 0.75\n",
      "traffic light 0.46\n",
      "traffic light 0.60\n",
      "traffic light 0.60\n",
      "traffic light 0.72\n",
      "traffic light 0.43\n",
      "traffic light 0.54\n",
      "traffic light 0.59\n",
      "traffic light 0.74\n",
      "traffic light 0.41\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.55\n",
      "traffic light 0.57\n",
      "traffic light 0.63\n",
      "traffic light 0.38\n",
      "traffic light 0.43\n",
      "traffic light 0.49\n",
      "traffic light 0.64\n",
      "traffic light 0.43\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.46\n",
      "traffic light 0.46\n",
      "traffic light 0.75\n",
      "traffic light 0.33\n",
      "traffic light 0.40\n",
      "traffic light 0.43\n",
      "traffic light 0.71\n",
      "traffic light 0.33\n",
      "traffic light 0.43\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.55\n",
      "traffic light 0.30\n",
      "traffic light 0.36\n",
      "traffic light 0.38\n",
      "traffic light 0.47\n",
      "[1. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "traffic light 0.76\n",
      "traffic light 0.33\n",
      "traffic light 0.40\n",
      "traffic light 0.48\n",
      "[1. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      "traffic light 0.71\n",
      "traffic light 0.33\n",
      "[1. 1. 0. 0. 1. 1. 1. 0. 0.]\n",
      "traffic light 0.41\n",
      "traffic light 0.48\n",
      "traffic light 0.82\n",
      "traffic light 0.36\n",
      "traffic light 0.39\n",
      "traffic light 0.45\n",
      "traffic light 0.46\n",
      "traffic light 0.75\n",
      "traffic light 0.32\n",
      "traffic light 0.33\n",
      "traffic light 0.41\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 0.]\n",
      "'''green!!!'''\n",
      "traffic light 0.52\n",
      "traffic light 0.52\n",
      "traffic light 0.59\n",
      "traffic light 0.81\n",
      "traffic light 0.33\n",
      "traffic light 0.40\n",
      "traffic light 0.42\n",
      "traffic light 0.48\n",
      "traffic light 0.56\n",
      "traffic light 0.73\n",
      "traffic light 0.75\n",
      "traffic light 0.44\n",
      "traffic light 0.71\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.75\n",
      "traffic light 0.31\n",
      "traffic light 0.34\n",
      "traffic light 0.58\n",
      "traffic light 0.69\n",
      "[0. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.30\n",
      "traffic light 0.31\n",
      "traffic light 0.35\n",
      "traffic light 0.46\n",
      "[0. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.70\n",
      "traffic light 0.73\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.40\n",
      "traffic light 0.52\n",
      "traffic light 0.61\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.43\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.60\n",
      "traffic light 0.60\n",
      "traffic light 0.44\n",
      "traffic light 0.53\n",
      "traffic light 0.70\n",
      "traffic light 0.35\n",
      "traffic light 0.39\n",
      "traffic light 0.48\n",
      "traffic light 0.82\n",
      "traffic light 0.45\n",
      "traffic light 0.58\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.82\n",
      "traffic light 0.62\n",
      "traffic light 0.70\n",
      "traffic light 0.47\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.75\n",
      "traffic light 0.44\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.79\n",
      "traffic light 0.58\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.75\n",
      "traffic light 0.54\n",
      "traffic light 0.70\n",
      "traffic light 0.50\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.84\n",
      "traffic light 0.48\n",
      "traffic light 0.58\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.86\n",
      "traffic light 0.75\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.82\n",
      "traffic light 0.71\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.78\n",
      "traffic light 0.41\n",
      "traffic light 0.80\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.81\n",
      "traffic light 0.32\n",
      "traffic light 0.33\n",
      "traffic light 0.40\n",
      "traffic light 0.66\n",
      "traffic light 0.75\n",
      "traffic light 0.34\n",
      "traffic light 0.37\n",
      "traffic light 0.44\n",
      "traffic light 0.61\n",
      "traffic light 0.66\n",
      "traffic light 0.71\n",
      "traffic light 0.42\n",
      "traffic light 0.47\n",
      "traffic light 0.71\n",
      "traffic light 0.82\n",
      "traffic light 0.34\n",
      "traffic light 0.39\n",
      "traffic light 0.52\n",
      "traffic light 0.80\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.88\n",
      "traffic light 0.34\n",
      "traffic light 0.36\n",
      "traffic light 0.46\n",
      "traffic light 0.56\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.87\n",
      "traffic light 0.53\n",
      "traffic light 0.55\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.81\n",
      "traffic light 0.32\n",
      "traffic light 0.45\n",
      "traffic light 0.77\n",
      "traffic light 0.54\n",
      "traffic light 0.56\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.74\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.37\n",
      "traffic light 0.46\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.62\n",
      "traffic light 0.31\n",
      "traffic light 0.33\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.82\n",
      "traffic light 0.32\n",
      "traffic light 0.35\n",
      "traffic light 0.44\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.85\n",
      "traffic light 0.41\n",
      "traffic light 0.59\n",
      "traffic light 0.86\n",
      "traffic light 0.51\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.63\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "traffic light 0.83\n",
      "traffic light 0.32\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "traffic light 0.36\n",
      "traffic light 0.49\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "traffic light 0.88\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "traffic light 0.35\n",
      "[0. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "traffic light 0.50\n",
      "traffic light 0.79\n",
      "[0. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "traffic light 0.30\n",
      "traffic light 0.59\n",
      "[0. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
      "traffic light 0.65\n",
      "traffic light 0.35\n",
      "[0. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
      "traffic light 0.59\n",
      "traffic light 0.37\n",
      "[0. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
      "traffic light 0.72\n",
      "traffic light 0.31\n",
      "traffic light 0.37\n",
      "traffic light 0.40\n",
      "[0. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "traffic light 0.68\n",
      "traffic light 0.42\n",
      "traffic light 0.47\n",
      "traffic light 0.53\n",
      "[0. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "traffic light 0.73\n",
      "traffic light 0.32\n",
      "traffic light 0.35\n",
      "traffic light 0.39\n",
      "traffic light 0.61\n",
      "[0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.83\n",
      "traffic light 0.34\n",
      "traffic light 0.40\n",
      "traffic light 0.68\n",
      "[0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.78\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.69\n",
      "traffic light 0.32\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.33\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.56\n",
      "traffic light 0.32\n",
      "traffic light 0.43\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.52\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.31\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.71\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.38\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.71\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.60\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.57\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.49\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.34\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.45\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.71\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.53\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.64\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.80\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.75\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.77\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.61\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.85\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.69\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.89\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.87\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.69\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.87\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.57\n",
      "traffic light 0.32\n",
      "traffic light 0.55\n",
      "traffic light 0.30\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.62\n",
      "traffic light 0.83\n",
      "traffic light 0.74\n",
      "traffic light 0.83\n",
      "traffic light 0.79\n",
      "traffic light 0.83\n",
      "traffic light 0.87\n",
      "traffic light 0.61\n",
      "traffic light 0.63\n",
      "traffic light 0.89\n",
      "traffic light 0.76\n",
      "traffic light 0.78\n",
      "traffic light 0.72\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.71\n",
      "traffic light 0.30\n",
      "traffic light 0.88\n",
      "traffic light 0.93\n",
      "traffic light 0.39\n",
      "traffic light 0.89\n",
      "traffic light 0.93\n",
      "traffic light 0.85\n",
      "[1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.90\n",
      "traffic light 0.78\n",
      "traffic light 0.79\n",
      "traffic light 0.85\n",
      "traffic light 0.81\n",
      "[1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.72\n",
      "traffic light 0.79\n",
      "traffic light 0.68\n",
      "[1. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "traffic light 0.77\n",
      "[1. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "traffic light 0.57\n",
      "traffic light 0.90\n",
      "traffic light 0.81\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "traffic light 0.77\n",
      "traffic light 0.76\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "'''red!!!'''\n",
      "traffic light 0.68\n",
      "traffic light 0.84\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.84\n",
      "traffic light 0.75\n",
      "traffic light 0.92\n",
      "traffic light 0.88\n",
      "traffic light 0.88\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.86\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.83\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.86\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.88\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.88\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.83\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.85\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.87\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.87\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.88\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.88\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.87\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.87\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.87\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.88\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.86\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.88\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.86\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.88\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.91\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.88\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.80\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.81\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.87\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.86\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.83\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.84\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.89\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.86\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.83\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.89\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.84\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.82\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.86\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.86\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.84\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.82\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.84\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.81\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.85\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.85\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.83\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.81\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.82\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.80\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.78\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.75\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.64\n",
      "traffic light 0.37\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "traffic light 0.63\n",
      "[0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "traffic light 0.81\n",
      "[0. 0. 0. 1. 1. 1. 0. 0. 0.]\n",
      "traffic light 0.68\n",
      "[0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "traffic light 0.54\n",
      "[0. 0. 0. 1. 1. 1. 1. 1. 0.]\n",
      "'''green!!!'''\n",
      "traffic light 0.65\n",
      "[0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.59\n",
      "[1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.60\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.60\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.54\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.52\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.46\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.57\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.61\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.64\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.68\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.58\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.57\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.58\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.53\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.58\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.32\n",
      "traffic light 0.42\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "traffic light 0.49\n",
      "traffic light 0.42\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "traffic light 0.59\n",
      "traffic light 0.32\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "traffic light 0.62\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "traffic light 0.58\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "traffic light 0.62\n",
      "traffic light 0.36\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "traffic light 0.61\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "traffic light 0.63\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "traffic light 0.74\n",
      "traffic light 0.31\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "traffic light 0.74\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.87\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.72\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.74\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.67\n",
      "traffic light 0.34\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.63\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.66\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.54\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.62\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.39\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.43\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.57\n",
      "traffic light 0.42\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.81\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.46\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.34\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.58\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.68\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.66\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.75\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.34\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.76\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.37\n",
      "traffic light 0.71\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "traffic light 0.38\n",
      "sum eachtime:37.155479057575576\n",
      "All time:51.61410247697495\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start3 = timer()\n",
    "    detect_img(YOLO())\n",
    "    end3 = timer()\n",
    "    print(\"All time:\" + str(end3 - start3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
