{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import colorsys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n",
    "from yolo3.utils import letterbox_image\n",
    "from keras.utils import multi_gpu_model\n",
    "gpu_num=1\n",
    "\n",
    "#- Added\n",
    "import cv2\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('../../movie2/media.io_IMG_5088.mp4')\n",
    "camera_scale = 1.\n",
    "#-\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide into car, walker, others\n",
    "model = load_model('history/use_res_12.h5')\n",
    "\n",
    "# color range\n",
    "lower_red = [[140,50,50],[0,50,50]]\n",
    "upper_red = [[180,255,255],[10,255,255]]\n",
    "\n",
    "lower_green = [35, 50, 50]\n",
    "upper_green = [95, 255, 255]\n",
    "\n",
    "# setting the threshold\n",
    "threshold = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO(object):\n",
    "    def __init__(self):\n",
    "        self.model_path = '../../model_data/yolo.h5' # model path or trained weights path\n",
    "        self.anchors_path = '../../model_data/yolo_anchors.txt'\n",
    "        self.classes_path = '../../model_data/coco_classes.txt'\n",
    "        self.score = 0.3\n",
    "        self.iou = 0.45\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.model_image_size = (416, 416) # fixed size or (None, None), hw\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "        self.count = 0\n",
    "        self.num = 0\n",
    "        self.zeroarray = np.zeros(25)\n",
    "\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        if gpu_num>=2:\n",
    "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=gpu_num)\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def detect_image(self, image):\n",
    "        start = timer()\n",
    "\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "\n",
    "        font = ImageFont.truetype(font='../../font/FiraMono-Medium.otf',\n",
    "                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "        thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "            if predicted_class == 'traffic light':\n",
    "                label = '{} {:.2f}'.format(predicted_class, score)\n",
    "                draw = ImageDraw.Draw(image)\n",
    "                label_size = draw.textsize(label, font)\n",
    "\n",
    "                top, left, bottom, right = box\n",
    "                top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "                left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "                bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "                right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "                cropped_img = image.crop((left, top, right, bottom))\n",
    "                file_name = f\"../../img_data/rectangle/{self.count}.jpg\"\n",
    "                \n",
    "                new_img = pil2cv(cropped_img)\n",
    "                resize_img = np.array(cv2pil(cv2.resize(preprocess(new_img), dsize=(32, 32))))/255.0\n",
    "                data = resize_img.reshape((1, 32, 32, 3))\n",
    "#                 pred = model.predict(data)\n",
    "#                 bestnum  = 0.0\n",
    "#                 bestclass = 0\n",
    "#                 for n in [0,1,2,3]:\n",
    "#                     if bestnum < pred[0][n]:\n",
    "#                         bestnum = pred[0][n]\n",
    "#                         bestclass = n\n",
    "#                 #color_prediction\n",
    "#                 if (bestclass==0) or (bestclass==1):\n",
    "                red = color_extraction(cropped_img, 'red', lower_red, upper_red)\n",
    "                green = color_extraction(cropped_img, 'green', lower_green, upper_green)\n",
    "\n",
    "                red_ratio = color_ratio(red, \"red\", threshold)\n",
    "                green_ratio = color_ratio(green,  \"green\", threshold)\n",
    "                string = color_predict(red_ratio, green_ratio)\n",
    "                majority(string, self.zeroarray, self.num)\n",
    "                self.num += 1\n",
    "                self.count += 1\n",
    "\n",
    "                if top - label_size[1] >= 0:\n",
    "                    text_origin = np.array([left, top - label_size[1]])\n",
    "                else:\n",
    "                    text_origin = np.array([left, top + 1])\n",
    "\n",
    "                # My kingdom for a good redistributable image drawing library.\n",
    "                for i in range(thickness):\n",
    "                    draw.rectangle(\n",
    "                        [left + i, top + i, right - i, bottom - i],\n",
    "                        outline=self.colors[c])\n",
    "                draw.rectangle(\n",
    "                    [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                    fill=self.colors[c])\n",
    "                draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "                del draw\n",
    "\n",
    "                end = timer()\n",
    "        return image\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_img(yolo):\n",
    "    while True:\n",
    "        ret, image = cap.read()\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            break\n",
    "        h, w = image.shape[:2]\n",
    "        rh = int(h * camera_scale)\n",
    "        rw = int(w * camera_scale)\n",
    "        image = cv2.resize(image, (rw, rh))\n",
    "        image = image[:,:,(2,1,0)]\n",
    "        image = Image.fromarray(image)\n",
    "        r_image = yolo.detect_image(image)\n",
    "        out_img = np.array(r_image)[:,:,(2,1,0)]\n",
    "        cv2.imshow(\"YOLOv2\", np.array(out_img))\n",
    "#         cv2.waitKey(0)\n",
    "    yolo.close_session()\n",
    "\n",
    "def preprocess(img):\n",
    "    h, w, c = img.shape\n",
    "    longest_edge = max(h, w)\n",
    "    top = 0\n",
    "    bottom = 0\n",
    "    left = 0\n",
    "    right = 0\n",
    "    if h < longest_edge:\n",
    "        diff_h = longest_edge - h\n",
    "        top = diff_h // 2\n",
    "        bottom = diff_h - top\n",
    "    elif w < longest_edge:\n",
    "        diff_w = longest_edge - w\n",
    "        left = diff_w // 2\n",
    "        right = diff_w - left\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right,\n",
    "                             cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    return img\n",
    "\n",
    "def cv2pil(image):\n",
    "    ''' OpenCV型 -> PIL型 '''\n",
    "    new_image = image.copy()\n",
    "    if new_image.ndim == 2:  # モノクロ\n",
    "        pass\n",
    "    elif new_image.shape[2] == 3:  # カラー\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)\n",
    "    elif new_image.shape[2] == 4:  # 透過\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_BGRA2RGBA)\n",
    "    new_image = Image.fromarray(new_image)\n",
    "    return new_image\n",
    "\n",
    "def pil2cv(image):\n",
    "    ''' PIL型 -> OpenCV型 '''\n",
    "    new_image = np.array(image, dtype=np.uint8)\n",
    "    if new_image.ndim == 2:  # モノクロ\n",
    "        pass\n",
    "    elif new_image.shape[2] == 3:  # カラー\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR)\n",
    "    elif new_image.shape[2] == 4:  # 透過\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGBA2BGRA)\n",
    "    return new_image\n",
    "\n",
    "#Phase2:color extracting\n",
    "#create color mask\n",
    "def create_mask(color:str, lower_color:list, upper_color:list, img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    if color == 'red':\n",
    "        lower_red1 = np.array(lower_color[0])\n",
    "        upper_red1 = np.array(upper_color[0])\n",
    "        lower_red2 = np.array(lower_color[1])\n",
    "        upper_red2 = np.array(upper_color[1])\n",
    "        red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "        red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "        mask = red_mask1 + red_mask2\n",
    "    else:\n",
    "        lower_color = np.array(lower_color)\n",
    "        upper_color = np.array(upper_color)\n",
    "        mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    return mask\n",
    "\n",
    "#create pics extracted the paricular color\n",
    "def color_extraction(cropped_img:list, color:str, lower_color:list, upper_color:list):\n",
    "    img = pil2cv(cropped_img)\n",
    "    mask = create_mask(color, lower_color, upper_color, img)\n",
    "    target = cv2.bitwise_and(img, img, mask=mask)\n",
    "    return target\n",
    "\n",
    "def color_ratio(color_pic:str, color:str, threshold:int):\n",
    "    img = cv2.cvtColor(color_pic, cv2.COLOR_RGB2GRAY)\n",
    "    ret, img_thresh = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n",
    "    colorPixels = cv2.countNonZero(img_thresh)\n",
    "    wholeSize = img.size\n",
    "    color_ratio = colorPixels/wholeSize*100\n",
    "    return color_ratio\n",
    "\n",
    "\n",
    "def color_predict(red:list, green:list):\n",
    "    if red > green:\n",
    "        if red > 5:\n",
    "            return('Red')\n",
    "        else:\n",
    "            return('NaN')\n",
    "    elif green > red:            \n",
    "        if green > 5:\n",
    "            return('Green')\n",
    "        else:\n",
    "            return('NaN')\n",
    "    else:\n",
    "        return('NaN')\n",
    "\n",
    "\n",
    "def majority(string:str, zerolist:list, num:int):\n",
    "    if num < 25:\n",
    "        fps = num\n",
    "    else:\n",
    "        fps = num - (num // 25) * 25\n",
    "#     print(string)\n",
    "    if 'Red' in string:\n",
    "        zerolist[fps] = 0\n",
    "    elif 'Green' in string:\n",
    "        zerolist[fps] = 1\n",
    "    else:\n",
    "        zerolist[fps] = 'NaN'\n",
    "    if fps == 24:\n",
    "        nans = np.count_nonzero(np.isnan(zerolist))\n",
    "        ones = np.count_nonzero(zerolist)-nans\n",
    "        zeros = zerolist.shape[0]-ones-nans\n",
    "\n",
    "        if (zeros > ones):\n",
    "            print(\"'''Red!!!'''\")\n",
    "        elif (ones > zeros):\n",
    "            print(\"'''Green!!!'''\")\n",
    "        else:\n",
    "            print(\"'''idk!!!'''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../model_data/yolo.h5 model, anchors, and classes loaded.\n",
      "'''Green!!!'''\n",
      "'''Green!!!'''\n",
      "'''Green!!!'''\n",
      "'''Green!!!'''\n",
      "'''Green!!!'''\n",
      "'''Green!!!'''\n",
      "'''Green!!!'''\n",
      "'''Red!!!'''\n",
      "'''idk!!!'''\n",
      "'''Green!!!'''\n",
      "'''Green!!!'''\n",
      "'''Red!!!'''\n",
      "'''Red!!!'''\n",
      "'''Red!!!'''\n",
      "'''Red!!!'''\n",
      "'''Red!!!'''\n",
      "'''Red!!!'''\n",
      "'''Red!!!'''\n",
      "'''Red!!!'''\n",
      "'''Red!!!'''\n",
      "'''Red!!!'''\n",
      "'''Green!!!'''\n",
      "'''Red!!!'''\n",
      "'''Red!!!'''\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ddc8d88e3dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdetect_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-53cb4ad77ec4>\u001b[0m in \u001b[0;36mdetect_img\u001b[0;34m(yolo)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mrh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcamera_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mrw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcamera_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    detect_img(YOLO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
