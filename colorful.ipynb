{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import colorsys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n",
    "from yolo3.utils import letterbox_image\n",
    "from keras.utils import multi_gpu_model\n",
    "gpu_num=1\n",
    "\n",
    "#- Added\n",
    "import cv2\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('../../gopro/021405.mp4')\n",
    "camera_scale = 1.\n",
    "#-\n",
    "\n",
    "import csv\n",
    "import glob \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mutagen.mp3 import MP3 as mp3\n",
    "import pygame\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import Process\n",
    "import multiprocessing as multi\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"../../img_data\"\n",
    "\n",
    "# devide into car, walker, others\n",
    "model = load_model('history/use_res_12.h5')\n",
    "\n",
    "# color range\n",
    "# lower_red = [[150,30,255],[0,30,255]]\n",
    "# upper_red = [[180,255,255],[20,255,255]]\n",
    "\n",
    "# lower_green = [45, 30, 255]\n",
    "# upper_green = [90, 255, 255]\n",
    "lower_red = [[150,80,80],[0,80,80]]\n",
    "upper_red = [[180,255,255],[20,255,255]]\n",
    "\n",
    "lower_green = [40, 80, 80]\n",
    "upper_green = [95, 255, 255]\n",
    "\n",
    "\n",
    "# setting the threshold\n",
    "threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class YOLO(object):\n",
    "#     def __init__(self):\n",
    "#         start1 = timer()\n",
    "#         self.model_path = '../../model_data/yolo.h5' # model path or trained weights path\n",
    "#         self.anchors_path = '../../model_data/yolo_anchors.txt'\n",
    "#         self.classes_path = '../../model_data/coco_classes.txt'\n",
    "#         self.score = 0.3\n",
    "#         self.iou = 0.45\n",
    "#         self.class_names = self._get_class()\n",
    "#         self.anchors = self._get_anchors()\n",
    "#         self.sess = K.get_session()\n",
    "#         self.model_image_size = (416, 416) # fixed size or (None, None), hw\n",
    "#         self.boxes, self.scores, self.classes = self.generate()\n",
    "#         self.count = 0\n",
    "#         self.num = 0\n",
    "#         self.zeroarray = np.zeros(30)\n",
    "#         self.flag = 3*np.ones(100)\n",
    "#         self.passtime = 0\n",
    "#         self.colorval = {0:(46, 230, 199), 1:(220, 20, 60), 2:(20, 159, 219), 3:(119, 136, 153), 4:(179, 158, 54)}\n",
    "#         self.predclass = {0:'green', 1:'red', 2:'car', 3:'others', 4:'sub'}\n",
    "#         end1 = timer()\n",
    "#         print(\"init time:\" + str(end1 - start1))\n",
    "\n",
    "#     def _get_class(self):\n",
    "#         classes_path = os.path.expanduser(self.classes_path)\n",
    "#         with open(classes_path) as f:\n",
    "#             class_names = f.readlines()\n",
    "#         class_names = [c.strip() for c in class_names]\n",
    "#         return class_names\n",
    "\n",
    "#     def _get_anchors(self):\n",
    "#         anchors_path = os.path.expanduser(self.anchors_path)\n",
    "#         with open(anchors_path) as f:\n",
    "#             anchors = f.readline()\n",
    "#         anchors = [float(x) for x in anchors.split(',')]\n",
    "#         return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "#     def generate(self):\n",
    "#         model_path = os.path.expanduser(self.model_path)\n",
    "#         assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "#         # Load model, or construct model and load weights.\n",
    "#         num_anchors = len(self.anchors)\n",
    "#         num_classes = len(self.class_names)\n",
    "#         is_tiny_version = num_anchors==6 # default setting\n",
    "#         try:\n",
    "#             self.yolo_model = load_model(model_path, compile=False)\n",
    "#         except:\n",
    "#             self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "#                 if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "#             self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "#         else:\n",
    "#             assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "#                 num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "#                 'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "#         print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "#         # Generate colors for drawing bounding boxes.\n",
    "#         hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "#                       for x in range(len(self.class_names))]\n",
    "#         self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "#         self.colors = list(\n",
    "#             map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "#                 self.colors))\n",
    "#         np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "#         np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "#         np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "#         # Generate output tensor targets for filtered bounding boxes.\n",
    "#         self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "#         if gpu_num>=2:\n",
    "#             self.yolo_model = multi_gpu_model(self.yolo_model, gpus=gpu_num)\n",
    "#         boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "#                 len(self.class_names), self.input_image_shape,\n",
    "#                 score_threshold=self.score, iou_threshold=self.iou)\n",
    "#         return boxes, scores, classes\n",
    "\n",
    "#     def detect_image(self, image):\n",
    "#         start = timer()\n",
    "\n",
    "#         if self.model_image_size != (None, None):\n",
    "#             assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "#             assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "#             boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "#         else:\n",
    "#             new_image_size = (image.width - (image.width % 32),\n",
    "#                               image.height - (image.height % 32))\n",
    "#             boxed_image = letterbox_image(image, new_image_size)\n",
    "#         image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "# #         print(image_data.shape)\n",
    "#         image_data /= 255.\n",
    "#         image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "#         out_boxes, out_scores, out_classes = self.sess.run(\n",
    "#             [self.boxes, self.scores, self.classes],\n",
    "#             feed_dict={\n",
    "#                 self.yolo_model.input: image_data,\n",
    "#                 self.input_image_shape: [image.size[1], image.size[0]],\n",
    "#                 K.learning_phase(): 0\n",
    "#             })\n",
    "\n",
    "# #         print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "#         font = ImageFont.truetype(font='../../font/FiraMono-Medium.otf',\n",
    "#                     size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "#         thickness = (image.size[0] + image.size[1]) // 300\n",
    "#         for i, c in reversed(list(enumerate(out_classes))):\n",
    "#             predicted_class = self.class_names[c]\n",
    "#             box = out_boxes[i]\n",
    "#             score = out_scores[i]\n",
    "#             if predicted_class == 'traffic light':                \n",
    "# #                 label = '{} {:.2f}'.format(predicted_class, score)\n",
    "#                 top, left, bottom, right = box\n",
    "#                 top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "#                 left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "#                 bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "#                 right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "#                 cropped_img = image.crop((left, top, right, bottom))\n",
    "# #                 file_name = f\"../../img_data/rectangle/{self.count}.jpg\"\n",
    "                \n",
    "#                 # remove car traffic light and other noise\n",
    "#                 new_img = pil2cv(cropped_img)\n",
    "#                 resize_img = np.array(cv2pil(cv2.resize(preprocess(new_img), dsize=(32, 32))))/255.0\n",
    "#                 data = resize_img.reshape((1, 32, 32, 3))\n",
    "#                 pred = model.predict(data)\n",
    "#                 bestnum  = 0.0\n",
    "#                 bestclass = 0\n",
    "#                 for n in [0,1,2,3]:\n",
    "#                     if bestnum < pred[0][n]:\n",
    "#                         bestnum = pred[0][n]\n",
    "#                         bestclass = n\n",
    "#                 #color_prediction\n",
    "                \n",
    "#                 if (bestclass==0) or (bestclass==1):\n",
    "#                     red = color_extraction(cropped_img, 'red', lower_red, upper_red)\n",
    "#                     green = color_extraction(cropped_img, 'green', lower_green, upper_green)\n",
    "#                     red_ratio = color_ratio(red, \"red\", threshold)\n",
    "#                     green_ratio = color_ratio(green,  \"green\", threshold)\n",
    "#                     string = color_predict(red_ratio, green_ratio)\n",
    "#                     if string == 'NaN':\n",
    "#                         bestclass = 4\n",
    "#                     elif string == 'Green':\n",
    "#                         bestclass = 0\n",
    "#                     else:\n",
    "#                         bestclass = 1\n",
    "#                     judge_count, new_flag = majority(string, self.zeroarray, self.num)\n",
    "#                     self.flag[judge_count] = new_flag\n",
    "#                     if self.flag[judge_count-1] != new_flag:\n",
    "#                         cmd = f\"python soundon.py {new_flag}\"\n",
    "# #                         print(self.flag)\n",
    "#                         if self.flag[judge_count-1]!=3:\n",
    "#                             cmd2 = f\"python soundon.py {3}\"\n",
    "#                             subprocess.Popen(cmd2.split())\n",
    "#                         if new_flag == 0:\n",
    "#                             color_print(new_flag)\n",
    "#                             subprocess.Popen(cmd.split())\n",
    "#                         elif new_flag == 1:\n",
    "#                             subprocess.Popen(cmd.split())\n",
    "#                             color_print(new_flag)\n",
    "#                         else:\n",
    "# #                             subprocess.Popen(cmd.split())\n",
    "#                             color_print(new_flag)\n",
    "#                     self.num += 1\n",
    "#                     self.count += 1\n",
    "                \n",
    "#                 label = '{} {:.2f}'.format(self.predclass[bestclass], score)\n",
    "#                 draw = ImageDraw.Draw(image)\n",
    "#                 label_size = draw.textsize(label, font)\n",
    "\n",
    "\n",
    "#                 if top - label_size[1] >= 0:\n",
    "#                     text_origin = np.array([left, top - label_size[1]])\n",
    "#                 else:\n",
    "#                     text_origin = np.array([left, top + 1])\n",
    "\n",
    "#                 # My kingdom for a good redistributable image drawing library.\n",
    "#                 for i in range(thickness):\n",
    "#                     draw.rectangle(\n",
    "#                         [left + i, top + i, right - i, bottom - i],\n",
    "#                         outline=self.colorval[bestclass])\n",
    "#                 draw.rectangle(\n",
    "#                     [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "#                     fill=self.colorval[bestclass])\n",
    "#                 draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "#                 del draw\n",
    "\n",
    "#                 end = timer()\n",
    "#                 dur = end - start \n",
    "#         return image\n",
    "\n",
    "#     def close_session(self):\n",
    "#         self.sess.close()\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO(object):\n",
    "    def __init__(self):\n",
    "        start1 = timer()\n",
    "        self.model_path = '../../model_data/yolo.h5' # model path or trained weights path\n",
    "        self.anchors_path = '../../model_data/yolo_anchors.txt'\n",
    "        self.classes_path = '../../model_data/coco_classes.txt'\n",
    "        self.score = 0.3\n",
    "        self.iou = 0.45\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.model_image_size = (416, 416) # fixed size or (None, None), hw\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "        self.count = 0\n",
    "        self.num = 0\n",
    "        self.zeroarray = np.zeros(9)\n",
    "        self.flag = 3*np.ones(100)\n",
    "        self.passtime = 0\n",
    "        self.colorval = {0:(46, 230, 199), 1:(220, 20, 60), 2:(20, 159, 219), 3:(119, 136, 153), 4:(179, 158, 54)}\n",
    "        self.predclass = {0:'green', 1:'red', 2:'car', 3:'others', 4:'sub'}\n",
    "        end1 = timer()\n",
    "        print(\"init time:\" + str(end1 - start1))\n",
    "\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        np.random.seed(None)  # Reset seed to default.\n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        if gpu_num>=2:\n",
    "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=gpu_num)\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def detect_image(self, image):\n",
    "        start = timer()\n",
    "\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "#         print(image_data.shape)\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "\n",
    "#         print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "        font = ImageFont.truetype(font='../../font/FiraMono-Medium.otf',\n",
    "                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "        thickness = (image.size[0] + image.size[1]) // 300\n",
    "        instant = 0\n",
    "        othercount = 0\n",
    "        otherinfo = np.zeros((15, 6))\n",
    "        boxinfo = np.zeros((15, 7))\n",
    "        sizeinfo = np.zeros(15)\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "            if predicted_class == 'traffic light':                \n",
    "#                 label = '{} {:.2f}'.format(predicted_class, score)\n",
    "                top, left, bottom, right = box\n",
    "                top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "                left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "                bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "                right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "                cropped_img = image.crop((left, top, right, bottom))\n",
    "#                 file_name = f\"../../img_data/rectangle/{self.count}.jpg\"\n",
    "                \n",
    "                # remove car traffic light and other noise\n",
    "                new_img = pil2cv(cropped_img)\n",
    "                resize_img = np.array(cv2pil(cv2.resize(preprocess(new_img), dsize=(32, 32))))/255.0\n",
    "                data = resize_img.reshape((1, 32, 32, 3))\n",
    "                pred = model.predict(data)\n",
    "                bestnum  = 0.0\n",
    "                bestclass = 0\n",
    "                for n in [0,1,2,3]:\n",
    "                    if bestnum < pred[0][n]:\n",
    "                        bestnum = pred[0][n]\n",
    "                        bestclass = n\n",
    "                #color_prediction\n",
    "                if (bestclass==2) or (bestclass==3):\n",
    "                    otherinfo[othercount] += [left, right, top, bottom, score, bestclass]\n",
    "                    othercount += 1\n",
    "                    \n",
    "                \n",
    "                if (bestclass==0) or (bestclass==1):\n",
    "                    width = left - right\n",
    "                    height = top - bottom\n",
    "                    size = width * height\n",
    "                    boxinfo[instant] += [size, left, right, top, bottom, score, bestclass]\n",
    "                    sizeinfo[instant] += boxinfo[instant][0]\n",
    "                    instant += 1\n",
    "                    \n",
    "        for i in range(othercount+instant):\n",
    "            if i < othercount:\n",
    "                left, right, top, bottom, score, bestclass = otherinfo[i]\n",
    "                label = '{} {:.2f}'.format(self.predclass[bestclass], score)\n",
    "                draw = ImageDraw.Draw(image)\n",
    "                label_size = draw.textsize(label, font)\n",
    "\n",
    "\n",
    "                if top - label_size[1] >= 0:\n",
    "                    text_origin = np.array([left, top - label_size[1]])\n",
    "                else:\n",
    "                    text_origin = np.array([left, top + 1])\n",
    "\n",
    "                # My kingdom for a good redistributable image drawing library.\n",
    "                for i in range(thickness):\n",
    "                    draw.rectangle(\n",
    "                        [left + i, top + i, right - i, bottom - i],\n",
    "                        outline=self.colorval[bestclass])\n",
    "                draw.rectangle(\n",
    "                    [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                    fill=self.colorval[bestclass])\n",
    "                draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "            else:\n",
    "                key = np.argmax(sizeinfo)\n",
    "                size, left, right, top, bottom, score, bestclass = boxinfo[i-othercount]\n",
    "#                 print(f\"{i-othercount}:{size}\")\n",
    "                if i == key+othercount:\n",
    "                    red = color_extraction(cropped_img, 'red', lower_red, upper_red)\n",
    "                    green = color_extraction(cropped_img, 'green', lower_green, upper_green)\n",
    "                    red_ratio = color_ratio(red, \"red\", threshold)\n",
    "                    green_ratio = color_ratio(green,  \"green\", threshold)\n",
    "                    string = color_predict(red_ratio, green_ratio)\n",
    "                    if string == 'NaN':\n",
    "                        bestclass = 4\n",
    "                    elif string == 'Green':\n",
    "                        bestclass = 0\n",
    "                    elif string == 'Red':\n",
    "                        bestclass = 1\n",
    "                    judge_count, new_flag = majority(string, self.zeroarray, self.num)\n",
    "                    self.flag[judge_count] = new_flag\n",
    "                    if self.flag[judge_count-1] != new_flag:\n",
    "                        cmd = f\"python soundon.py {new_flag}\"\n",
    "#                         print(self.flag)\n",
    "                        if self.flag[judge_count-1]!=3:\n",
    "                            cmd2 = f\"python soundon.py {3}\"\n",
    "                            subprocess.Popen(cmd2.split())\n",
    "                        if new_flag == 0:\n",
    "                            color_print(new_flag)\n",
    "                            subprocess.Popen(cmd.split())\n",
    "                        elif new_flag == 1:\n",
    "                            subprocess.Popen(cmd.split())\n",
    "                            color_print(new_flag)\n",
    "                        else:\n",
    "#                             subprocess.Popen(cmd.split())\n",
    "                            color_print(new_flag)\n",
    "                    self.num += 1\n",
    "                else:\n",
    "                    bestclass = 4\n",
    "#                 self.count += 1\n",
    "                \n",
    "                label = '{} {:.2f}'.format(self.predclass[bestclass], score)\n",
    "                draw = ImageDraw.Draw(image)\n",
    "                label_size = draw.textsize(label, font)\n",
    "\n",
    "\n",
    "                if top - label_size[1] >= 0:\n",
    "                    text_origin = np.array([left, top - label_size[1]])\n",
    "                else:\n",
    "                    text_origin = np.array([left, top + 1])\n",
    "\n",
    "                # My kingdom for a good redistributable image drawing library.\n",
    "                for i in range(thickness):\n",
    "                    draw.rectangle(\n",
    "                        [left + i, top + i, right - i, bottom - i],\n",
    "                        outline=self.colorval[bestclass])\n",
    "                draw.rectangle(\n",
    "                    [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                    fill=self.colorval[bestclass])\n",
    "                draw.text(text_origin, label, fill=(60, 60, 60), font=font)\n",
    "                del draw\n",
    "\n",
    "                end = timer()\n",
    "                dur = end - start \n",
    "        return image\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_img(yolo):\n",
    "    num = 0\n",
    "    tm = cv2.TickMeter()\n",
    "    tm.start()\n",
    "\n",
    "    fps = 0\n",
    "    sumtime = 0\n",
    "    tdf = 0\n",
    "    flame = 0\n",
    "    dfa = np.zeros((10000))\n",
    "    yoloFlag = True\n",
    "    flagnum = 0\n",
    "    \n",
    "    while True:\n",
    "        start2 = timer()\n",
    "        ret, image = cap.read()\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            break\n",
    "        if ret == False:\n",
    "            break\n",
    "        if yoloFlag:\n",
    "            if flagnum > 0:\n",
    "                for i in range(20):\n",
    "                    cv2.rectangle(image,(120-6*i,20-i),(120+6*i, 20+i),(60,60,60),5)\n",
    "#                 cv2.rectangle(image,(0,0),(160,40),(40,40,40),3,-1)ret, image = cap.read()\n",
    "                fps = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#                 fps = cap.get(cv2.CAP_PROP_POS_FRAMES)/cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#                 fps *= 1000\n",
    "                fps /= 1000\n",
    "                cv2.putText(image, 'timecode:{:.1f}'.format(fps),(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (220, 220, 220), thickness=2)\n",
    "                h, w = image.shape[:2]\n",
    "                rh = int(h * camera_scale)\n",
    "                rw = int(w * camera_scale)\n",
    "                image = cv2.resize(image, (rw, rh))\n",
    "                image = image[:,:,(2,1,0)]\n",
    "                image = Image.fromarray(image)\n",
    "                r_image = yolo.detect_image(image)\n",
    "                out_img = np.array(r_image)[:,:,(2,1,0)]\n",
    "                cv2.imshow(\"YOLOv2\", np.array(out_img))\n",
    "                end2 = timer()\n",
    "                eachtime = end2 - start2\n",
    "                tdf += eachtime - 1/30\n",
    "                sumtime += eachtime\n",
    "                if tdf*30 > 1:\n",
    "                    dfa[flagnum] += int(tdf*30)\n",
    "                    yoloFlag = False\n",
    "                    flagnum += 1\n",
    "            else:\n",
    "                fps = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                fps /= 1000\n",
    "                cv2.putText(image, 'timecode: {:.1f}'.format(fps),(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), thickness=2)\n",
    "                h, w = image.shape[:2]\n",
    "                rh = int(h * camera_scale)\n",
    "                rw = int(w * camera_scale)\n",
    "                image = cv2.resize(image, (rw, rh))\n",
    "                image = image[:,:,(2,1,0)]\n",
    "                image = Image.fromarray(image)\n",
    "                r_image = yolo.detect_image(image)\n",
    "                out_img = np.array(r_image)[:,:,(2,1,0)]\n",
    "                cv2.imshow(\"YOLOv2\", np.array(out_img))\n",
    "                end2 = timer()\n",
    "                eachtime = end2 - start2\n",
    "                if num == 1:\n",
    "                    tdf += eachtime - 1/30\n",
    "                    sumtime += eachtime\n",
    "                    if tdf*30 > 1:                        \n",
    "                        dfa[flagnum] += int(tdf*30)\n",
    "                        yoloFlag = False\n",
    "                        flagnum += 1\n",
    "        else:\n",
    "            end2_2 = timer()\n",
    "            eachtime = end2_2 - start2\n",
    "            sumtime += eachtime\n",
    "            tdf += eachtime\n",
    "            tdf -= 1/30\n",
    "            dfa[flagnum -1] -= 1\n",
    "            if dfa[flagnum-1] == 0:\n",
    "                yoloFlag = True\n",
    "        num += 1\n",
    "        \n",
    "    print('sum eachtime:' + str(sumtime))\n",
    "    yolo.close_session()\n",
    "            \n",
    "def numericalSort(value):\n",
    "    numbers = re.compile(r'(\\d+)')\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "def get_img_path(dir_name:str, version:str):\n",
    "    files = f\"{dir_name}/{version}/\"\n",
    "    img_path = sorted(glob.glob(str(files+\"*.jpg\")), key=numericalSort)\n",
    "    return img_path           \n",
    "\n",
    "def preprocess(img):\n",
    "    h, w, c = img.shape\n",
    "    longest_edge = max(h, w)\n",
    "    top = 0\n",
    "    bottom = 0\n",
    "    left = 0\n",
    "    right = 0\n",
    "    if h < longest_edge:\n",
    "        diff_h = longest_edge - h\n",
    "        top = diff_h // 2\n",
    "        bottom = diff_h - top\n",
    "    elif w < longest_edge:\n",
    "        diff_w = longest_edge - w\n",
    "        left = diff_w // 2\n",
    "        right = diff_w - left\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right,\n",
    "                             cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    return img\n",
    "\n",
    "def cv2pil(image):\n",
    "    ''' OpenCV型 -> PIL型 '''\n",
    "    new_image = image.copy()\n",
    "    if new_image.ndim == 2:  # モノクロ\n",
    "        pass\n",
    "    elif new_image.shape[2] == 3:  # カラー\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)\n",
    "    elif new_image.shape[2] == 4:  # 透過\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_BGRA2RGBA)\n",
    "    new_image = Image.fromarray(new_image)\n",
    "    return new_image\n",
    "\n",
    "def pil2cv(image):\n",
    "    ''' PIL型 -> OpenCV型 '''\n",
    "    new_image = np.array(image, dtype=np.uint8)\n",
    "    if new_image.ndim == 2:  # モノクロ\n",
    "        pass\n",
    "    elif new_image.shape[2] == 3:  # カラー\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR)\n",
    "    elif new_image.shape[2] == 4:  # 透過\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGBA2BGRA)\n",
    "    return new_image\n",
    "\n",
    "#Phase2:color extracting\n",
    "#create color mask\n",
    "def create_mask(color:str, lower_color:list, upper_color:list, img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    if color == 'red':\n",
    "        lower_red1 = np.array(lower_color[0])\n",
    "        upper_red1 = np.array(upper_color[0])\n",
    "        lower_red2 = np.array(lower_color[1])\n",
    "        upper_red2 = np.array(upper_color[1])\n",
    "        red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "        red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "        mask = red_mask1 + red_mask2\n",
    "    else:\n",
    "        lower_color = np.array(lower_color)\n",
    "        upper_color = np.array(upper_color)\n",
    "        mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    return mask\n",
    "\n",
    "def color_extraction(cropped_img:list, color:str, lower_color:list, upper_color:list):\n",
    "    img = pil2cv(cropped_img)\n",
    "    mask = create_mask(color, lower_color, upper_color, img)\n",
    "    target = cv2.bitwise_and(img, img, mask=mask)\n",
    "#     cv2.imwrite(f\"./{color}/{num}.jpg\", target)\n",
    "    return target\n",
    "        \n",
    "def color_ratio(color_pic:str, color:str, threshold:int):\n",
    "    img = cv2.cvtColor(color_pic, cv2.COLOR_RGB2GRAY)\n",
    "#     ret, img_thresh = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARYcv2.THRESH_OTSU)\n",
    "    ret, img_thresh = cv2.threshold(img, threshold, 255, cv2.THRESH_OTSU)\n",
    "    colorPixels = cv2.countNonZero(img_thresh)\n",
    "    wholeSize = img.size\n",
    "    color_ratio = colorPixels/wholeSize*100\n",
    "    return color_ratio\n",
    "\n",
    "def color_predict(red:list, green:list):\n",
    "    if red > green:\n",
    "        if red > 5:\n",
    "            return('Red')\n",
    "        else:\n",
    "            return('NaN')\n",
    "    elif green > red:            \n",
    "        if green > 5:\n",
    "            return('Green')\n",
    "        else:\n",
    "            return('NaN')\n",
    "    else:\n",
    "        return('NaN')\n",
    "\n",
    "\n",
    "def majority(string:str, zerolist:list, num:int):\n",
    "    frames = 9\n",
    "    print(zerolist)\n",
    "    if num < frames:\n",
    "        fps = num\n",
    "    else:\n",
    "        fps = num - (num // frames) * frames\n",
    "    if 'Red' in string:\n",
    "        zerolist[fps] = 0\n",
    "    elif 'Green' in string:\n",
    "        zerolist[fps] = 1\n",
    "#     else:\n",
    "#         zerolist[fps] = 'NaN'\n",
    "    if fps == frames-1:\n",
    "        nans = np.count_nonzero(np.isnan(zerolist))\n",
    "        ones = np.count_nonzero(zerolist)-nans\n",
    "        zeros = zerolist.shape[0]-ones-nans\n",
    "        judge_count = num // frames + 1\n",
    "        if (zeros > ones):\n",
    "            return judge_count, 0\n",
    "        elif (ones > zeros):\n",
    "            return judge_count, 1\n",
    "        else:\n",
    "            return judge_count, 2\n",
    "    else:\n",
    "        return 0, 3\n",
    "    \n",
    "def color_print(new_flag:int):\n",
    "    color = {0:\"'''red!!!'''\", 1:\"'''green!!!'''\", 2:\"'''idk!!!'''\"}\n",
    "    print(color[new_flag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../model_data/yolo.h5 model, anchors, and classes loaded.\n",
      "init time:10.63008276396431\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "'''green!!!'''\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 0. 0. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      "'''red!!!'''\n",
      "[1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "'''green!!!'''\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "sum eachtime:37.12538534356281\n",
      "All time:51.95127241697628\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start3 = timer()\n",
    "    detect_img(YOLO())\n",
    "    end3 = timer()\n",
    "    print(\"All time:\" + str(end3 - start3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
